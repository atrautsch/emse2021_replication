{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load separately classified data\n",
    "df1 = pd.read_csv('../data/mauczka_label_finished.csv')\n",
    "df2 = pd.read_csv('../data/mauczka_label_finished2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "df1.rename(columns={'label_internal_quality': 'label_internal_quality1', 'label_external_quality': 'label_external_quality1'}, inplace=True)\n",
    "df2.rename(columns={'label_internal_quality': 'label_internal_quality2', 'label_external_quality': 'label_external_quality2'}, inplace=True)\n",
    "df2.drop(columns=['project_url', 'message', 'internal_quality', 'external_quality', 'sw_adaptive', 'project', 'has_label'], inplace=True)\n",
    "dfj = df1.merge(df2, on='revision_hash', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set consensus label to NaN\n",
    "dfj['label_internal_quality'] = np.NaN\n",
    "dfj['label_external_quality'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for consensus labeling session\n",
    "dfj.to_csv('../data/mauczka_label_consensus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load finished consensus data\n",
    "cons = pd.read_csv('../data/mauczka_label_consensus_finished2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back, either we have committee decision which means label_internal/external_quality is bool.\n",
    "# if not the case it is NaN and we can overwrite with our consensus.\n",
    "idx = cons[(cons['label_internal_quality1'] == cons['label_internal_quality2']) & (cons['label_external_quality1'] == cons['label_external_quality2'])].index\n",
    "\n",
    "cons.loc[idx, 'label_internal_quality'] = cons.loc[idx, 'label_internal_quality1']\n",
    "cons.loc[idx, 'label_external_quality'] = cons.loc[idx, 'label_external_quality1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save consensus data with labels\n",
    "cons.to_csv('../data/mauczka_label_two_authors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read consensus data with labels\n",
    "cons = pd.read_csv('../data/mauczka_label_two_authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv for manual inspection for guideline differences\n",
    "cons[(cons['internal_quality'] != cons['label_internal_quality'])][['message', 'internal_quality', 'label_internal_quality']].to_csv('../data/internal.csv')\n",
    "cons[(cons['external_quality'] != cons['label_external_quality'])][['message', 'external_quality', 'label_external_quality']].to_csv('../data/external.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set identified guideline differences\n",
    "cons['guideline_differences'] = False\n",
    "\n",
    "# assert guideline differences for corrective\n",
    "# test addition or changes labeled as bug (6)\n",
    "cons.loc[201, 'guideline_differences'] = True\n",
    "cons.loc[210, 'guideline_differences'] = True\n",
    "cons.loc[213, 'guideline_differences'] = True\n",
    "cons.loc[244, 'guideline_differences'] = True\n",
    "cons.loc[284, 'guideline_differences'] = True\n",
    "cons.loc[316, 'guideline_differences'] = True\n",
    "\n",
    "# assert guideline differences for perfective\n",
    "# license changes labeled as perfective (15)\n",
    "cons.loc[0, 'guideline_differences'] = True\n",
    "cons.loc[1, 'guideline_differences'] = True\n",
    "cons.loc[2, 'guideline_differences'] = True\n",
    "cons.loc[3, 'guideline_differences'] = True\n",
    "cons.loc[4, 'guideline_differences'] = True\n",
    "cons.loc[5, 'guideline_differences'] = True\n",
    "cons.loc[6, 'guideline_differences'] = True\n",
    "cons.loc[57, 'guideline_differences'] = True\n",
    "cons.loc[61, 'guideline_differences'] = True\n",
    "cons.loc[71, 'guideline_differences'] = True\n",
    "cons.loc[75, 'guideline_differences'] = True\n",
    "cons.loc[109, 'guideline_differences'] = True\n",
    "cons.loc[124, 'guideline_differences'] = True\n",
    "cons.loc[221, 'guideline_differences'] = True\n",
    "cons.loc[249, 'guideline_differences'] = True\n",
    "\n",
    "# bugfix labeled as perfective (8)\n",
    "cons.loc[18, 'guideline_differences'] = True\n",
    "cons.loc[19, 'guideline_differences'] = True\n",
    "cons.loc[20, 'guideline_differences'] = True\n",
    "cons.loc[21, 'guideline_differences'] = True\n",
    "cons.loc[25, 'guideline_differences'] = True\n",
    "cons.loc[28, 'guideline_differences'] = True\n",
    "cons.loc[193, 'guideline_differences'] = True\n",
    "cons.loc[197, 'guideline_differences'] = True\n",
    "\n",
    "# repository work, merging, tagging labeled as perfective (13)\n",
    "cons.loc[24, 'guideline_differences'] = True\n",
    "cons.loc[37, 'guideline_differences'] = True\n",
    "cons.loc[38, 'guideline_differences'] = True\n",
    "cons.loc[152, 'guideline_differences'] = True\n",
    "cons.loc[160, 'guideline_differences'] = True\n",
    "cons.loc[161, 'guideline_differences'] = True\n",
    "cons.loc[162, 'guideline_differences'] = True\n",
    "cons.loc[163, 'guideline_differences'] = True\n",
    "cons.loc[164, 'guideline_differences'] = True\n",
    "cons.loc[165, 'guideline_differences'] = True\n",
    "cons.loc[166, 'guideline_differences'] = True\n",
    "cons.loc[167, 'guideline_differences'] = True\n",
    "cons.loc[168, 'guideline_differences'] = True\n",
    "\n",
    "# build configuration not labeled as perfective and release repository work (9)\n",
    "cons.loc[103, 'guideline_differences'] = True\n",
    "cons.loc[104, 'guideline_differences'] = True\n",
    "cons.loc[108, 'guideline_differences'] = True\n",
    "cons.loc[182, 'guideline_differences'] = True\n",
    "cons.loc[281, 'guideline_differences'] = True\n",
    "cons.loc[282, 'guideline_differences'] = True\n",
    "cons.loc[318, 'guideline_differences'] = True\n",
    "cons.loc[322, 'guideline_differences'] = True\n",
    "cons.loc[323, 'guideline_differences'] = True\n",
    "\n",
    "# empty commit message (2)\n",
    "cons.loc[66, 'guideline_differences'] = True\n",
    "cons.loc[128, 'guideline_differences'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined disagreements 70 / 286\n",
      "agreement percent 75.52447552447552\n"
     ]
    }
   ],
   "source": [
    "# show combined disagreement data\n",
    "consg = cons[cons['guideline_differences'] == False].copy()\n",
    "disagreements = consg[((consg['internal_quality'] != consg['label_internal_quality']) | (consg['external_quality'] != consg['label_external_quality']))]\n",
    "print('combined disagreements', len(disagreements), '/', len(consg))\n",
    "print('agreement percent', (len(consg) - len(disagreements)) * 100 / len(consg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6250698849067879"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = cons[cons['guideline_differences'] == False][['internal_quality', 'external_quality', 'label_internal_quality', 'label_external_quality']].copy()\n",
    "def cat1(row):\n",
    "    if row['internal_quality']:\n",
    "        return 'perfective'\n",
    "    if row['external_quality']:\n",
    "        return 'corrective'\n",
    "    return 'neither'\n",
    "\n",
    "def cat2(row):\n",
    "    if row['label_internal_quality']:\n",
    "        return 'perfective'\n",
    "    if row['label_external_quality']:\n",
    "        return 'corrective'\n",
    "    return 'neither'\n",
    "\n",
    "tmp['cat1_label'] = tmp.apply(cat1, axis=1)\n",
    "tmp['cat2_label'] = tmp.apply(cat2, axis=1)\n",
    "cohen_kappa_score(tmp['cat1_label'], tmp['cat2_label'], labels=['neither', 'corrective', 'perfective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.621105144072186"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show inter-rater agreement\n",
    "def user1(row):\n",
    "    if row['label_internal_quality1']:\n",
    "        return 'perfective'\n",
    "    if row['label_external_quality1']:\n",
    "        return 'corrective'\n",
    "    return 'neither'\n",
    "\n",
    "def user2(row):\n",
    "    if row['label_internal_quality2']:\n",
    "        return 'perfective'\n",
    "    if row['label_external_quality2']:\n",
    "        return 'corrective'\n",
    "    return 'neither'\n",
    "\n",
    "cdf = cons[['label_internal_quality1', 'label_external_quality1', 'label_internal_quality2', 'label_external_quality2']].copy()\n",
    "cdf['user1_label'] = cdf.apply(user1, axis=1)\n",
    "cdf['user2_label'] = cdf.apply(user2, axis=1)\n",
    "\n",
    "cohen_kappa_score(cdf['user1_label'], cdf['user2_label'], labels=['neither', 'corrective', 'perfective'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
